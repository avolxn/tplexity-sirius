import logging
from typing import Literal

from sentence_transformers import SentenceTransformer

from tplexity.retriever.utils import get_device

logger = logging.getLogger(__name__)


PromptNameType = Literal[
    "search_query",
    "search_document",
    "paraphrase",
    "categorize",
    "categorize_sentiment",
    "categorize_topic",
    "categorize_entailment",
]


class Embedding:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å embeddings –º–æ–¥–µ–ª–∏ ai-forever/FRIDA

    –ú–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - prompt_name –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á:
        - "search_query": –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º –ø–æ–∏—Å–∫–µ
        - "search_document": –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º –ø–æ–∏—Å–∫–µ
        - "paraphrase": –¥–ª—è —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (STS, –ø–∞—Ä–∞—Ñ—Ä–∞–∑—ã)
        - "categorize": –¥–ª—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        - "categorize_sentiment": –¥–ª—è –∑–∞–¥–∞—á, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–æ–º
        - "categorize_topic": –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ —Ç–µ–º–∞–º
        - "categorize_entailment": –¥–ª—è –∑–∞–¥–∞—á —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (NLI)
    - CLS pooling (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 512 —Ç–æ–∫–µ–Ω–æ–≤
    """

    def __init__(self, model_name: str = "ai-forever/FRIDA"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ Embedding

        Args:
            model_name (str): –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        """
        self.model_name = model_name
        device = get_device()
        logger.info(f"üîÑ [retriever][dense_embedding] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {model_name} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {device}")
        try:
            self.model = SentenceTransformer(model_name, device=str(device))
            logger.info(f"‚úÖ [retriever][dense_embedding] –ú–æ–¥–µ–ª—å {model_name} —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ {device}")
        except Exception as e:
            logger.error(f"‚ùå [retriever][dense_embedding] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def encode(
        self,
        texts: list[str] | str,
        prompt_name: PromptNameType = "search_query",
    ) -> list[list[float]] | list[float]:
        """
        –ö–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –≤ embeddings

        Args:
            texts (list[str] | str): –¢–µ–∫—Å—Ç –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
            prompt_name (PromptNameType): –ò–º—è –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∑–∞–¥–∞—á–∏:
                - "search_query": –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º –ø–æ–∏—Å–∫–µ
                - "search_document": –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–º –ø–æ–∏—Å–∫–µ
                - "paraphrase": –¥–ª—è —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (STS, –ø–∞—Ä–∞—Ñ—Ä–∞–∑—ã)
                - "categorize": –¥–ª—è –∞—Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                - "categorize_sentiment": –¥–ª—è –∑–∞–¥–∞—á, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–æ–º
                - "categorize_topic": –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ —Ç–µ–º–∞–º
                - "categorize_entailment": –¥–ª—è –∑–∞–¥–∞—á —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (NLI)

        Returns:
            list[list[float]] | list[float]: –°–ø–∏—Å–æ–∫ embeddings (–∏–ª–∏ –æ–¥–∏–Ω embedding, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç)
        """

        if isinstance(texts, str):
            texts = [texts]
            single_text = True
        else:
            single_text = False

        logger.debug(f"üîÑ [retriever][dense_embedding] –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤, prompt_name: {prompt_name}")
        embeddings = self.model.encode(texts, prompt_name=prompt_name, normalize_embeddings=True)

        if single_text:
            return embeddings[0].tolist() if hasattr(embeddings[0], "tolist") else embeddings[0]

        return [emb.tolist() if hasattr(emb, "tolist") else emb for emb in embeddings]

    def encode_query(self, query: str) -> list[float]:
        """
        –ö–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –≤ embedding

        Args:
            query (str): –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞

        Returns:
            list[float]: Embedding –∑–∞–ø—Ä–æ—Å–∞ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ float
        """
        logger.debug(f"üîÑ [retriever][dense_embedding] –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}...")
        return self.encode(query, prompt_name="search_query")

    def encode_document(self, documents: list[str]) -> list[list[float]]:
        """
        –ö–æ–¥–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ embeddings

        Args:
            documents (list[str]): –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

        Returns:
            list[list[float]]: –°–ø–∏—Å–æ–∫ embeddings –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        logger.debug(f"üîÑ [retriever][dense_embedding] –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        return self.encode(documents, prompt_name="search_document")

    def get_sentence_embedding_dimension(self) -> int | None:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings

        Returns:
            int | None: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
        """
        embedding_dim = self.model.get_sentence_embedding_dimension()

        if embedding_dim is None:
            logger.warning(
                "‚ö†Ô∏è [retriever][dense_embedding] –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ get_sentence_embedding_dimension(), –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏"
            )
            test_embedding = self.encode("test")
            embedding_dim = len(test_embedding)
            logger.info(f"‚úÖ [retriever][dense_embedding] –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏: {embedding_dim}")

        return embedding_dim

    def get_model(self) -> SentenceTransformer:
        """
        –ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ SentenceTransformer

        Returns:
            SentenceTransformer: –≠–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ SentenceTransformer
        """
        return self.model


_embedding_instance: Embedding | None = None


def get_embedding_model() -> Embedding:
    """
    –ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è embeddings (singleton)

    Returns:
        Embedding: –≠–∫–∑–µ–º–ø–ª—è—Ä Embedding –º–æ–¥–µ–ª–∏ ai-forever/FRIDA
    """
    global _embedding_instance
    if _embedding_instance is None:
        _embedding_instance = Embedding()
    return _embedding_instance
