import asyncio
import logging
import traceback
from typing import Literal
from uuid import uuid4

from qdrant_client import AsyncQdrantClient
from qdrant_client.models import (
    Distance,
    Fusion,
    FusionQuery,
    Modifier,
    PointIdsList,
    PointStruct,
    Prefetch,
    SparseVectorParams,
    VectorParams,
)

from tplexity.retriever.config import settings
from tplexity.retriever.dense_embedding import get_embedding_model
from tplexity.retriever.sparse_embedding import get_bm25_model

logger = logging.getLogger(__name__)


class VectorSearch:
    """–ö–ª–∞—Å—Å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ Qdrant —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π dense –∏ sparse –≤–µ–∫—Ç–æ—Ä–æ–≤"""

    def __init__(
        self,
        collection_name: str,
        host: str,
        port: int,
        api_key: str | None,
        prefetch_ratio: float,
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∞

        Args:
            collection_name (str): –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant
            host (str): –•–æ—Å—Ç Qdrant
            port (int): –ü–æ—Ä—Ç Qdrant
            api_key (str | None): API –∫–ª—é—á –¥–ª—è Qdrant
            prefetch_ratio (float): –í–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è prefetch
        """
        self.collection_name = collection_name
        self.host = host
        self.port = port
        self.api_key = api_key
        self.prefetch_ratio = prefetch_ratio

        logger.info("üîÑ [retriever][vector_search] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant")
        try:
            self.client = AsyncQdrantClient(
                url=f"https://{self.host}:{self.port}",
                api_key=self.api_key,
            )

            logger.info(f"‚úÖ [retriever][vector_search] –ö–ª–∏–µ–Ω—Ç Qdrant –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {self.host}:{self.port}")
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞ Qdrant: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

        self.embedding_model = get_embedding_model()
        self.embedding_dim = self.embedding_model.get_sentence_embedding_dimension()
        logger.info(f"‚úÖ [retriever][vector_search] Dense –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {self.embedding_dim}")

        self.bm25 = get_bm25_model()
        logger.info("‚úÖ [retriever][vector_search] BM25 –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    async def _ensure_collection(self) -> None:
        """–°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π dense –∏ sparse –≤–µ–∫—Ç–æ—Ä–æ–≤, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""

        try:
            collections = await self.client.get_collections()
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

        collection_names = [col.name for col in collections.collections]

        if self.collection_name not in collection_names:
            vectors_config = {
                "dense": VectorParams(
                    size=self.embedding_dim,
                    distance=Distance.COSINE,
                )
            }

            sparse_vectors_config = {
                "bm25": SparseVectorParams(
                    modifier=Modifier.IDF,
                ),
            }

            try:
                await self.client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=vectors_config,
                    sparse_vectors_config=sparse_vectors_config,
                )
                logger.info(
                    f"‚úÖ [retriever][vector_search] –ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} —Å–æ–∑–¥–∞–Ω–∞ —Å dense –∏ sparse –≤–µ–∫—Ç–æ—Ä–∞–º–∏"
                )
            except Exception as e:
                error_traceback = traceback.format_exc()
                logger.error(
                    f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {type(e).__name__}: {e}\n{error_traceback}",
                    exc_info=True,
                )
                raise
        else:
            logger.info(f"‚úÖ [retriever][vector_search] –ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

    async def add_documents(
        self,
        documents: list[str],
        ids: list[str] | None = None,
        metadatas: list[dict] | None = None,
    ) -> None:
        """
        –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å dense –∏ sparse –≤–µ–∫—Ç–æ—Ä–∞–º–∏

        Args:
            documents (list[str]): –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            ids (list[str] | None): –°–ø–∏—Å–æ–∫ ID –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è UUID
            metadatas (list[dict] | None): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞

        Raises:
            ValueError: –ï—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã
        """
        if not documents:
            raise ValueError("–°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

        if metadatas is None:
            metadatas = [{}] * len(documents)

        if len(metadatas) != len(documents):
            raise ValueError(
                f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ({len(metadatas)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ({len(documents)})"
            )

        if ids is None:
            ids = [str(uuid4()) for _ in documents]

        if len(ids) != len(set(ids)):
            raise ValueError("ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏")

        logger.debug(
            f"üîÑ [retriever][vector_search] –ù–∞—á–∞–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embeddings –¥–ª—è {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        )

        dense_embeddings, sparse_embeddings = await asyncio.gather(
            asyncio.to_thread(self.embedding_model.encode_document, documents),
            asyncio.to_thread(self.bm25.encode_documents, documents),
        )

        logger.debug(
            f"‚úÖ [retriever][vector_search] Embeddings —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã: dense={len(dense_embeddings)}, sparse={len(sparse_embeddings)}"
        )

        points = []
        for document_id, document, dense_emb, sparse_emb, metadata in zip(
            ids, documents, dense_embeddings, sparse_embeddings, metadatas, strict=False
        ):
            vectors = {
                "dense": dense_emb,
                "bm25": sparse_emb.as_object(),
            }
            payload = {"text": document, **metadata}

            points.append(PointStruct(id=document_id, vector=vectors, payload=payload))

        await self._ensure_collection()

        try:
            await self.client.upsert(collection_name=self.collection_name, points=points)
            logger.info(
                f"‚úÖ [retriever][vector_search] –î–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é {self.collection_name}"
            )
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Qdrant: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

    async def search(
        self,
        query: str,
        top_k: int = 10,
        search_type: Literal["dense", "sparse", "hybrid"] = "hybrid",
    ) -> list[tuple[str, float, str, dict | None]]:
        """
        –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø–æ–∏—Å–∫–∞

        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            search_type (Literal["dense", "sparse", "hybrid"]): –¢–∏–ø –ø–æ–∏—Å–∫–∞ (dense, sparse, hybrid). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é "hybrid"

        Returns:
            list[tuple[str, float, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, score, —Ç–µ–∫—Å—Ç, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)

        Raises:
            ValueError: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø—É—Å—Ç –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã
        """
        if not query or not query.strip():
            logger.warning("‚ö†Ô∏è [retriever][vector_search] –ü–µ—Ä–µ–¥–∞–Ω –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å")
            return []

        if top_k < 1:
            logger.error(f"‚ùå [retriever][vector_search] top_k –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å >= 1, –ø–æ–ª—É—á–µ–Ω–æ: {top_k}")
            return []

        if search_type == "hybrid":
            return await self._hybrid_search(query, top_k, self.prefetch_ratio)
        elif search_type == "dense":
            return await self._dense_search(query, top_k)
        elif search_type == "sparse":
            return await self._sparse_search(query, top_k)

    async def _dense_search(self, query: str, top_k: int) -> list[tuple[str, float, str, dict | None]]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ dense –≤–µ–∫—Ç–æ—Ä–∞–º

        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            list[tuple[str, float, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, score, —Ç–µ–∫—Å—Ç, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        """
        logger.debug(f"üîç [retriever][vector_search] –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ dense –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}...")
        query_embedding = await asyncio.to_thread(self.embedding_model.encode_query, query)

        try:
            search_results = await self.client.search(
                collection_name=self.collection_name,
                query_vector=("dense", query_embedding),
                limit=top_k,
                with_payload=True,
            )
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ dense –ø–æ–∏—Å–∫–µ: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

        results = []
        for result in search_results:
            text = result.payload.get("text", "")
            metadata = {k: v for k, v in result.payload.items() if k != "text"}
            results.append((str(result.id), float(result.score), text, metadata))

        return results

    async def _sparse_search(self, query: str, top_k: int) -> list[tuple[str, float, str, dict | None]]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ sparse –≤–µ–∫—Ç–æ—Ä–∞–º

        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            list[tuple[str, float, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, score, —Ç–µ–∫—Å—Ç, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        """
        logger.debug(f"üîç [retriever][vector_search] –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ sparse –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}...")
        query_embedding = await asyncio.to_thread(self.bm25.encode_query, query)

        try:
            search_results = await self.client.search(
                collection_name=self.collection_name,
                query_vector=("bm25", query_embedding),
                limit=top_k,
                with_payload=True,
            )
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ sparse –ø–æ–∏—Å–∫–µ: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

        results = []
        for result in search_results:
            text = result.payload.get("text", "")
            metadata = {k: v for k, v in result.payload.items() if k != "text"}
            results.append((str(result.id), float(result.score), text, metadata))

        return results

    async def _hybrid_search(
        self,
        query: str,
        top_k: int,
        prefetch_ratio: float,
    ) -> list[tuple[str, float, str, dict | None]]:
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º prefetch –∏ RRF

        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            prefetch_ratio (float): –í–æ —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –±–æ–ª—å—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è prefetch

        Returns:
            list[tuple[str, float, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (ID –¥–æ–∫—É–º–µ–Ω—Ç–∞, score, —Ç–µ–∫—Å—Ç, –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
        """
        logger.debug(f"üîç [retriever][vector_search] –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query[:50]}...")

        dense_query, sparse_query = await asyncio.gather(
            asyncio.to_thread(self.embedding_model.encode_query, query),
            asyncio.to_thread(self.bm25.encode_query, query),
        )

        prefetch = [
            Prefetch(
                query=dense_query,
                using="dense",
                limit=int(top_k * prefetch_ratio),
            ),
            Prefetch(
                query=sparse_query,
                using="bm25",
                limit=int(top_k * prefetch_ratio),
            ),
        ]

        try:
            search_results = await self.client.query_points(
                collection_name=self.collection_name,
                prefetch=prefetch,
                query=FusionQuery(
                    fusion=Fusion.RRF,
                ),
                with_payload=True,
                limit=top_k,
            )
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–º –ø–æ–∏—Å–∫–µ: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

        results = []
        for result in search_results.points:
            text = result.payload.get("text", "")
            metadata = {k: v for k, v in result.payload.items() if k != "text"}
            results.append((str(result.id), float(result.score), text, metadata))

        return results

    async def get_documents(self, doc_ids: list[str]) -> list[tuple[str, str, dict | None]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∏—Ö ID

        Args:
            doc_ids (list[str]): –°–ø–∏—Å–æ–∫ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

        Returns:
            list[tuple[str, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (doc_id, text, metadata)
        """
        if not doc_ids:
            logger.warning("‚ö†Ô∏è [retriever][vector_search] –ü–µ—Ä–µ–¥–∞–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ ID –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return []

        try:
            results = await self.client.retrieve(
                collection_name=self.collection_name,
                ids=doc_ids,
                with_payload=True,
            )

            documents = []
            for point in results:
                text = point.payload.get("text", "")
                metadata = {k: v for k, v in point.payload.items() if k != "text"}
                documents.append((str(point.id), text, metadata if metadata else None))

            logger.info(
                f"‚úÖ [retriever][vector_search] –ü–æ–ª—É—á–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {len(doc_ids)} –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö"
            )
            return documents
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

    async def get_all_documents(self) -> list[tuple[str, str, dict | None]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏

        Returns:
            list[tuple[str, str, dict | None]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (doc_id, text, metadata)
        """

        try:
            points, _ = await self.client.scroll(
                collection_name=self.collection_name,
                limit=None,
                with_payload=True,
            )

            documents = []
            for point in points:
                text = point.payload.get("text", "")
                metadata = {k: v for k, v in point.payload.items() if k != "text"}
                documents.append((str(point.id), text, metadata if metadata else None))

            logger.info(f"‚úÖ [retriever][vector_search] –ü–æ–ª—É—á–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
            return documents
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

    async def delete_documents(self, ids: list[str]) -> None:
        """
        –£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ –∏—Ö ID

        Args:
            ids (list[str]): –°–ø–∏—Å–æ–∫ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        """
        if not ids:
            logger.warning("‚ö†Ô∏è [retriever][vector_search] –ü–µ—Ä–µ–¥–∞–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ ID –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
            return

        logger.info(f"üîÑ [retriever][vector_search] –£–¥–∞–ª–µ–Ω–∏–µ {len(ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {self.collection_name}")

        try:
            await self.client.delete(
                collection_name=self.collection_name,
                points_selector=PointIdsList(points=ids),
            )
            logger.info(
                f"‚úÖ [retriever][vector_search] –£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ {len(ids)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {self.collection_name}"
            )
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ Qdrant: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise

    async def delete_all_documents(self) -> None:
        """–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        logger.warning("‚ö†Ô∏è [retriever][vector_search] –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏")

        try:
            await self.client.delete_collection(collection_name=self.collection_name)
            logger.info(f"‚úÖ [retriever][vector_search] –ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} —É–¥–∞–ª–µ–Ω–∞")
            await self._ensure_collection()
            logger.info(f"‚úÖ [retriever][vector_search] –ö–æ–ª–ª–µ–∫—Ü–∏—è {self.collection_name} –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∞")
        except Exception as e:
            error_traceback = traceback.format_exc()
            logger.error(
                f"‚ùå [retriever][vector_search] –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {type(e).__name__}: {e}\n{error_traceback}",
                exc_info=True,
            )
            raise
