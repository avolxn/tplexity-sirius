import logging
import re

from fastembed import SparseTextEmbedding
from pymorphy3 import MorphAnalyzer
from qdrant_client.models import SparseVector

logger = logging.getLogger(__name__)


class BM25:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å BM25 –ø–æ–∏—Å–∫–æ–º —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏"""

    def __init__(self, model_name: str = "Qdrant/bm25"):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25 –º–æ–¥–µ–ª–∏ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π

        Args:
            model_name (str): –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è sparse embeddings. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é "Qdrant/bm25"
        """
        self.model_name = model_name

        logger.info(f"üîÑ [retriever][sparse_embedding] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BM25 –º–æ–¥–µ–ª–∏: {model_name}")
        try:
            self.sparse_model = SparseTextEmbedding(model_name=model_name)
            logger.info(f"‚úÖ [retriever][sparse_embedding] Sparse –º–æ–¥–µ–ª—å (BM25) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {model_name}")
        except Exception as e:
            logger.error(f"‚ùå [retriever][sparse_embedding] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ sparse –º–æ–¥–µ–ª–∏: {e}")
            raise

        try:
            self.morph = MorphAnalyzer()
            logger.info("‚úÖ [retriever][sparse_embedding] –õ–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä (pymorphy3) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è BM25")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [retriever][sparse_embedding] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä: {e}")
            self.morph = None

    def lemmatize_text(self, text: str) -> str:
        """
        –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ BM25 –ø–æ–∏—Å–∫–∞

        Args:
            text (str): –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            str: –¢–µ–∫—Å—Ç —Å –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        """
        if self.morph is None:
            return text

        words = re.findall(r"[–∞-—è—ë–ê-–Ø–Åa-zA-Z]+", text.lower())
        lemmatized_words = []

        for word in words:
            if not word:
                continue
            try:
                parsed = self.morph.parse(word)[0]
                lemma = parsed.normal_form
                lemmatized_words.append(lemma)
            except Exception:
                lemmatized_words.append(word)

        return " ".join(lemmatized_words)

    def encode_documents(self, documents: list[str]) -> list[SparseVector]:
        """
        –°–æ–∑–¥–∞—Ç—å sparse embeddings –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π

        Args:
            documents (list[str]): –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

        Returns:
            list[SparseEmbedding]: –°–ø–∏—Å–æ–∫ sparse embeddings
        """
        lemmatized_documents = [self.lemmatize_text(doc) for doc in documents]
        sparse_embeddings = list(self.sparse_model.passage_embed(lemmatized_documents))
        return sparse_embeddings

    def encode_query(self, query: str) -> SparseVector:
        """
        –°–æ–∑–¥–∞—Ç—å sparse embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π

        Args:
            query (str): –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å

        Returns:
            SparseVector: SparseVector –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        """
        lemmatized_query = self.lemmatize_text(query)
        sparse_query_dict = list(self.sparse_model.query_embed(lemmatized_query))[0].as_object()
        return SparseVector(**sparse_query_dict)


_bm25_instance: BM25 | None = None


def get_bm25_model() -> BM25:
    """
    –ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è BM25 (singleton)

    Returns:
        BM25: –≠–∫–∑–µ–º–ø–ª—è—Ä BM25 –º–æ–¥–µ–ª–∏
    """
    global _bm25_instance
    if _bm25_instance is None:
        _bm25_instance = BM25()
    return _bm25_instance
