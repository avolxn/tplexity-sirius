import asyncio
import logging
from datetime import UTC, datetime, timedelta
from pathlib import Path

import httpx

from tplexity.parser.config import settings
from tplexity.parser.telegram_downloader import TelegramDownloader

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


async def clear_database(retriever_url: str) -> bool:
    """
    –û—á–∏—â–∞–µ—Ç –ë–î, —É–¥–∞–ª—è—è –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.

    Args:
        retriever_url: URL retriever API

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    try:
        delete_url = f"{retriever_url.rstrip('/')}/v1/retriever/documents/all"
        logger.info(f"üóëÔ∏è [parser][load_historical_posts] –û—á–∏—Å—Ç–∫–∞ –ë–î: {delete_url}")

        async with httpx.AsyncClient() as client:
            response = await client.delete(delete_url, timeout=60.0)
            response.raise_for_status()

        logger.info("‚úÖ [parser][load_historical_posts] –ë–î —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞")
        return True
    except Exception as e:
        logger.error(f"‚ùå [parser][load_historical_posts] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ë–î: {e}")
        return False


async def send_posts_to_retriever(
    posts: list[dict],
    channel: str,
    retriever_url: str,
    batch_size: int = 50,
    channel_titles: dict[str, str] | None = None,
) -> tuple[int, int]:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç—ã –≤ retriever (–±–µ–∑ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ–ª–Ω–æ—Å—Ç—å—é).

    Args:
        posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        channel: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞
        retriever_url: URL retriever API
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (—É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ, –æ—à–∏–±–æ–∫)
    """
    if not posts:
        return 0, 0

    documents_url = f"{retriever_url.rstrip('/')}/v1/retriever/documents"
    success_count = 0
    error_count = 0

    for i in range(0, len(posts), batch_size):
        batch = posts[i : i + batch_size]
        documents = []

        for post in batch:
            text = (post.get("text") or "").strip()
            if not text:
                continue

            date_str = post.get("date")
            if date_str:
                try:
                    if date_str.endswith("Z"):
                        date_str = date_str.replace("Z", "+00:00")

                    if "T" in date_str:
                        post_date = datetime.fromisoformat(date_str)
                    else:
                        post_date = datetime.fromisoformat(f"{date_str}T00:00:00")

                    formatted_date = post_date.strftime("%Y-%m-%d %H:%M:%S")
                    text = f"{text}\n\n{formatted_date}"
                except (ValueError, AttributeError) as e:
                    logger.debug(
                        f"‚ö†Ô∏è [parser][load_historical_posts] –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {date_str}, –æ—à–∏–±–∫–∞: {e}"
                    )

            metadata = {k: v for k, v in post.items() if k != "text"}
            metadata["channel_name"] = channel

            if channel_titles:
                channel_title = channel_titles.get(channel, channel)
                metadata["channel_title"] = channel_title
            else:
                metadata["channel_title"] = channel

            documents.append({"text": text, "metadata": metadata})

        if not documents:
            continue

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(documents_url, json={"documents": documents}, timeout=60.0)
                response.raise_for_status()
                success_count += len(documents)
                logger.info(
                    f"üì§ [parser][load_historical_posts] –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {len(documents)} –ø–æ—Å—Ç–æ–≤ –∏–∑ {channel} "
                    f"(–±–∞—Ç—á {i // batch_size + 1}/{(len(posts) + batch_size - 1) // batch_size})"
                )
        except Exception as e:
            error_count += len(documents)
            logger.error(f"‚ùå [parser][load_historical_posts] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –±–∞—Ç—á–∞ –∏–∑ {channel}: {e}")

    return success_count, error_count


async def load_historical_posts():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å—Ç–æ–≤."""
    logger.info("üöÄ [parser][load_historical_posts] –ó–∞–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –ø–æ—Å—Ç–æ–≤")

    if not settings.api_id or not settings.api_hash:
        logger.error("‚ùå [parser][load_historical_posts] –ù–µ —É–∫–∞–∑–∞–Ω—ã API_ID –∏–ª–∏ API_HASH –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    channels_list = settings.get_channels_list()
    if not channels_list:
        logger.error("‚ùå [parser][load_historical_posts] –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –ø—É—Å—Ç")
        return

    if not settings.webhook_url:
        logger.error("‚ùå [parser][load_historical_posts] –ù–µ —É–∫–∞–∑–∞–Ω WEBHOOK_URL –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return

    retriever_url = settings.webhook_url.rsplit("/retriever", 1)[0]
    logger.info(f"üì° [parser][load_historical_posts] Retriever URL: {retriever_url}")
    logger.info(f"üìã [parser][load_historical_posts] –ö–∞–Ω–∞–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {', '.join(channels_list)}")

    four_months_ago = datetime.now(UTC) - timedelta(days=120)
    logger.info(
        f"üìÖ [parser][load_historical_posts] –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç—ã —Å {four_months_ago.strftime('%Y-%m-%d %H:%M:%S UTC')}"
    )

    if not await clear_database(retriever_url):
        logger.error("‚ùå [parser][load_historical_posts] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –ë–î, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
        return

    project_root = Path(__file__).parent.parent.parent.parent
    session_path = project_root / settings.session_name

    logger.info("=" * 60)
    logger.info("üìã [parser][load_historical_posts] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è:")
    logger.info(f"   API_ID: {settings.api_id}")
    logger.info(f"   API_HASH: {'*' * 10 if settings.api_hash else 'None (–Ω–µ —É–∫–∞–∑–∞–Ω!)'}")
    logger.info(f"   SESSION_NAME: {settings.session_name}")
    logger.info(
        f"   TELEGRAM_SESSION_STRING: {'—É–∫–∞–∑–∞–Ω' if settings.session_string else '–Ω–µ —É–∫–∞–∑–∞–Ω (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ñ–∞–π–ª)'}"
    )

    if settings.session_string:
        logger.info(
            f"üîë [parser][load_historical_posts] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞ —Å–µ—Å—Å–∏–∏ (–¥–ª–∏–Ω–∞: {len(settings.session_string)} —Å–∏–º–≤–æ–ª–æ–≤)"
        )
        logger.debug(
            f"üîë [parser][load_historical_posts] –ü–µ—Ä–≤—ã–µ 20 —Å–∏–º–≤–æ–ª–æ–≤ session_string: {settings.session_string[:20]}..."
        )
    else:
        logger.info(f"üìÅ [parser][load_historical_posts] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏: {session_path}")
        if session_path.exists():
            logger.info(
                f"üìÅ [parser][load_historical_posts] –§–∞–π–ª —Å–µ—Å—Å–∏–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Ä–∞–∑–º–µ—Ä: {session_path.stat().st_size} –±–∞–π—Ç"
            )
        else:
            logger.warning(f"‚ö†Ô∏è [parser][load_historical_posts] –§–∞–π–ª —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {session_path}")
            logger.warning(
                "üí° [parser][load_historical_posts] –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Ç—Ä–æ–∫–∏ —Å–µ—Å—Å–∏–∏ –¥–æ–±–∞–≤—å—Ç–µ TELEGRAM_SESSION_STRING –≤ .env"
            )
            logger.warning(
                "üí° [parser][load_historical_posts] –ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: poetry run python src/tplexity/parser/authorize_telegram.py"
            )
    logger.info("=" * 60)

    logger.info("üîç [parser][load_historical_posts] –ü–ï–†–ï–î —Å–æ–∑–¥–∞–Ω–∏–µ–º TelegramDownloader:")
    logger.info(f"   settings.session_string type: {type(settings.session_string)}")
    logger.info(f"   settings.session_string value: {settings.session_string}")
    logger.info(f"   settings.session_string is None: {settings.session_string is None}")
    logger.info(f"   settings.session_string == '': {settings.session_string == ''}")
    if settings.session_string:
        logger.info(f"   settings.session_string.strip() == '': {settings.session_string.strip() == ''}")
        logger.info(f"   settings.session_string –¥–ª–∏–Ω–∞: {len(settings.session_string)}")

    logger.info("üîß [parser][load_historical_posts] –°–æ–∑–¥–∞–Ω–∏–µ TelegramDownloader...")
    downloader = TelegramDownloader(
        api_id=settings.api_id,
        api_hash=settings.api_hash,
        session_name=str(session_path),
        session_string=settings.session_string,
        download_path=str(project_root / settings.data_dir / "telegram"),
    )

    try:
        logger.info("üîå [parser][load_historical_posts] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Telegram...")
        try:
            await downloader.client.connect()
            logger.info("‚úÖ [parser][load_historical_posts] –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Telegram —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå [parser][load_historical_posts] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ Telegram: {e}", exc_info=True)
            return

        logger.info("üîç [parser][load_historical_posts] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        is_authorized = await downloader.client.is_user_authorized()
        logger.info(f"üîç [parser][load_historical_posts] –°—Ç–∞—Ç—É—Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {is_authorized}")

        if not is_authorized:
            error_msg = (
                "Telegram –∫–ª–∏–µ–Ω—Ç –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω. –¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è.\n"
                f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {'—Å—Ç—Ä–æ–∫–∞ —Å–µ—Å—Å–∏–∏' if settings.session_string else f'—Ñ–∞–π–ª —Å–µ—Å—Å–∏–∏ ({session_path})'}\n"
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç: poetry run python src/tplexity/parser/authorize_telegram.py"
            )
            logger.error(f"‚ùå [parser][load_historical_posts] {error_msg}")
            return

        logger.info("‚úÖ [parser][load_historical_posts] –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Telegram –∏ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ")

        total_posts_downloaded = 0
        total_posts_sent = 0
        total_errors = 0

        channel_titles: dict[str, str] = {}
        for channel in channels_list:
            try:
                entity = await downloader.client.get_entity(channel)
                channel_title = getattr(entity, "title", None) or channel
                channel_titles[channel] = channel_title
                logger.info(f"üì∫ [parser][load_historical_posts] –ö–∞–Ω–∞–ª {channel}: –Ω–∞–∑–≤–∞–Ω–∏–µ '{channel_title}'")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [parser][load_historical_posts] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ {channel}: {e}")
                channel_titles[channel] = channel

        for channel_idx, channel in enumerate(channels_list, 1):
            logger.info(
                f"\n{'=' * 60}\n"
                f"üì• [parser][load_historical_posts] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–Ω–∞–ª–∞ {channel_idx}/{len(channels_list)}: {channel}\n"
                f"{'=' * 60}"
            )

            try:
                logger.info(f"üì• [parser][load_historical_posts] –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –∏–∑ {channel}...")
                all_messages = []

                async for message in downloader.client.iter_messages(
                    channel,
                    limit=None,
                    offset_date=None,
                    reverse=False,
                ):
                    if not hasattr(message, "date") or not message.date:
                        continue

                    if message.date < four_months_ago:
                        break

                    message_dict = await downloader._message_to_dict(message, channel)
                    all_messages.append(message_dict)

                    if len(all_messages) % 100 == 0:
                        logger.info(
                            f"  üì• [parser][load_historical_posts] –°–∫–∞—á–∞–Ω–æ {len(all_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {channel}..."
                        )

                messages_with_text = [
                    msg
                    for msg in all_messages
                    if msg.get("text") and isinstance(msg.get("text"), str) and msg.get("text").strip()
                ]

                total_posts_downloaded += len(messages_with_text)
                logger.info(
                    f"üìä [parser][load_historical_posts] –ö–∞–Ω–∞–ª {channel}: "
                    f"—Å–∫–∞—á–∞–Ω–æ {len(all_messages)} –ø–æ—Å—Ç–æ–≤, "
                    f"{len(messages_with_text)} —Å —Ç–µ–∫—Å—Ç–æ–º"
                )

                if messages_with_text:
                    success, errors = await send_posts_to_retriever(
                        messages_with_text, channel, retriever_url, channel_titles=channel_titles
                    )
                    total_posts_sent += success
                    total_errors += errors

                    logger.info(
                        f"‚úÖ [parser][load_historical_posts] –ö–∞–Ω–∞–ª {channel}: "
                        f"–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {success} –ø–æ—Å—Ç–æ–≤, –æ—à–∏–±–æ–∫: {errors}"
                    )
                else:
                    logger.warning(f"‚ö†Ô∏è [parser][load_historical_posts] –ö–∞–Ω–∞–ª {channel}: –Ω–µ—Ç –ø–æ—Å—Ç–æ–≤ —Å —Ç–µ–∫—Å—Ç–æ–º")

            except Exception as e:
                logger.error(
                    f"‚ùå [parser][load_historical_posts] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–∞–ª–∞ {channel}: {e}", exc_info=True
                )
                total_errors += 1

        logger.info(
            f"\n{'=' * 60}\n"
            f"‚úÖ [parser][load_historical_posts] –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
            f"{'=' * 60}\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n"
            f"  - –í—Å–µ–≥–æ —Å–∫–∞—á–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {total_posts_downloaded}\n"
            f"  - –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –ë–î: {total_posts_sent}\n"
            f"  - –û—à–∏–±–æ–∫: {total_errors}\n"
            f"{'=' * 60}"
        )

    except Exception as e:
        logger.error(f"‚ùå [parser][load_historical_posts] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
    finally:
        try:
            await downloader.disconnect()
            logger.info("‚úÖ [parser][load_historical_posts] –û—Ç–∫–ª—é—á–µ–Ω–æ –æ—Ç Telegram")
        except Exception as e:
            logger.error(f"‚ùå [parser][load_historical_posts] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏: {e}")


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞."""
    asyncio.run(load_historical_posts())


if __name__ == "__main__":
    main()
