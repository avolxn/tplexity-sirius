{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ ReAct Router\n",
    "\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –≤—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã ReAct Router:\n",
    "- Recall (–ü–æ–ª–Ω–æ—Ç–∞)\n",
    "- Precision (–¢–æ—á–Ω–æ—Å—Ç—å)\n",
    "- F1-score\n",
    "- TP, FP, TN, FN (Confusion Matrix)\n",
    "\n",
    "ReAct Router —Ä–µ—à–∞–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ retriever –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(f\"üìÅ –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tplexity.generation.config import settings\n",
    "from tplexity.generation.generation_service import GenerationService\n",
    "\n",
    "print(\"‚úÖ –ò–º–ø–æ—Ä—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "dataset_path = project_root / \"data\" / \"data_18.11.25\" / \"react_router_dataset.json\"\n",
    "\n",
    "with open(dataset_path, encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(f\"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(dataset)}\")\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä –∑–∞–ø–∏—Å–∏:\")\n",
    "print(json.dumps(dataset[0], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GenerationService\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º GenerationService\n",
    "generation_service = GenerationService(\n",
    "    retriever_url=settings.retriever_api_url,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ GenerationService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n",
    "print(f\"   Router LLM Provider: {generation_service.router_llm_provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_router_prediction(query: str, llm_provider: str | None = None) -> Literal[\"YES\", \"NO\"]:\n",
    "    \"\"\"\n",
    "    –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ReAct Router –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞.\n",
    "\n",
    "    Args:\n",
    "        query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "        llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è\n",
    "\n",
    "    Returns:\n",
    "        \"YES\" –µ—Å–ª–∏ –Ω—É–∂–µ–Ω retriever, \"NO\" –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω\n",
    "    \"\"\"\n",
    "    use_retriever = await generation_service._should_use_retriever(\n",
    "        query=query,\n",
    "        session_id=None,  # –ë–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞\n",
    "        llm_provider=\"qwen\",\n",
    "    )\n",
    "    return \"YES\" if use_retriever else \"NO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û—Ü–µ–Ω–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evaluate_dataset(dataset: list[dict], batch_size: int = 10) -> list[dict]:\n",
    "    \"\"\"\n",
    "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
    "\n",
    "    Args:\n",
    "        dataset: –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "\n",
    "    Returns:\n",
    "        –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i : i + batch_size]\n",
    "\n",
    "        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ\n",
    "        tasks = []\n",
    "        for record in batch:\n",
    "            query = record[\"query\"]\n",
    "            task = get_router_prediction(query)\n",
    "            tasks.append(task)\n",
    "\n",
    "        predictions = await asyncio.gather(*tasks)\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        for record, prediction in zip(batch, predictions, strict=False):\n",
    "            expected = record.get(\"expected_router_decision\", \"YES\" if record.get(\"requires_rag\", True) else \"NO\")\n",
    "            requires_rag = record.get(\"requires_rag\", expected == \"YES\")\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"query\": record[\"query\"],\n",
    "                    \"expected\": expected,\n",
    "                    \"requires_rag\": requires_rag,\n",
    "                    \"predicted\": prediction,\n",
    "                    \"correct\": prediction == expected,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if (i + batch_size) % 100 == 0 or i + batch_size >= len(dataset):\n",
    "            print(f\"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {min(i + batch_size, len(dataset))} / {len(dataset)}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É\n",
    "print(f\"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞ {len(dataset)} –∑–∞–ø—Ä–æ—Å–∞—Ö...\")\n",
    "results = await evaluate_dataset(dataset, batch_size=50)\n",
    "print(\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results: list[dict]) -> dict:\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\n",
    "\n",
    "    Args:\n",
    "        results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏\n",
    "\n",
    "    Returns:\n",
    "        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏\n",
    "    \"\"\"\n",
    "    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º TP, FP, TN, FN\n",
    "    # –î–ª—è ReAct Router:\n",
    "    # - YES –æ–∑–Ω–∞—á–∞–µ—Ç \"–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever\" (positive class)\n",
    "    # - NO –æ–∑–Ω–∞—á–∞–µ—Ç \"–Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever\" (negative class)\n",
    "\n",
    "    tp = 0  # True Positive: predicted=YES, actual=YES (requires_rag=True)\n",
    "    fp = 0  # False Positive: predicted=YES, actual=NO (requires_rag=False)\n",
    "    tn = 0  # True Negative: predicted=NO, actual=NO (requires_rag=False)\n",
    "    fn = 0  # False Negative: predicted=NO, actual=YES (requires_rag=True)\n",
    "\n",
    "    for result in results:\n",
    "        predicted = result[\"predicted\"]\n",
    "        requires_rag = result[\"requires_rag\"]\n",
    "\n",
    "        if predicted == \"YES\" and requires_rag:\n",
    "            tp += 1\n",
    "        elif predicted == \"YES\" and not requires_rag:\n",
    "            fp += 1\n",
    "        elif predicted == \"NO\" and not requires_rag:\n",
    "            tn += 1\n",
    "        elif predicted == \"NO\" and requires_rag:\n",
    "            fn += 1\n",
    "\n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"tp\": tp,\n",
    "        \"fp\": fp,\n",
    "        \"tn\": tn,\n",
    "        \"fn\": fn,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"total\": len(results),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "metrics = calculate_metrics(results)\n",
    "\n",
    "print(\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ ReAct Router:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {metrics['total']}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"  TP (True Positive):  {metrics['tp']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\")\n",
    "print(f\"  FP (False Positive): {metrics['fp']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ YES, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\")\n",
    "print(f\"  TN (True Negative):  {metrics['tn']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ NO\")\n",
    "print(f\"  FN (False Negative): {metrics['fn']:4d}  |  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ NO,  —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ YES\")\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏:\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f}  (TP / (TP + FP))\")\n",
    "print(f\"  Recall:    {metrics['recall']:.4f}  (TP / (TP + FN))\")\n",
    "print(f\"  F1-score:  {metrics['f1']:.4f}\")\n",
    "print(f\"  Accuracy:  {metrics['accuracy']:.4f}  ((TP + TN) / Total)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# –û—à–∏–±–∫–∏ —Ç–∏–ø–∞ FP (False Positive)\n",
    "fp_errors = df[(df[\"predicted\"] == \"YES\") & (df[\"requires_rag\"] is False)]\n",
    "print(f\"\\n‚ùå False Positive (FP) –æ—à–∏–±–∫–∏: {len(fp_errors)}\")\n",
    "print(\"   Router —Ä–µ—à–∏–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ —ç—Ç–æ –±—ã–ª–æ –Ω–µ –Ω—É–∂–Ω–æ\")\n",
    "if len(fp_errors) > 0:\n",
    "    print(\"\\n–ü—Ä–∏–º–µ—Ä—ã FP –æ—à–∏–±–æ–∫:\")\n",
    "    for idx, row in fp_errors.head(5).iterrows():\n",
    "        print(f\"\\n  {idx + 1}. {row['query'][:100]}...\")\n",
    "\n",
    "# –û—à–∏–±–∫–∏ —Ç–∏–ø–∞ FN (False Negative)\n",
    "fn_errors = df[(df[\"predicted\"] == \"NO\") & (df[\"requires_rag\"] is True)]\n",
    "print(f\"\\n‚ùå False Negative (FN) –æ—à–∏–±–∫–∏: {len(fn_errors)}\")\n",
    "print(\"   Router —Ä–µ—à–∏–ª –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å retriever, –Ω–æ –æ–Ω –±—ã–ª –Ω—É–∂–µ–Ω\")\n",
    "if len(fn_errors) > 0:\n",
    "    print(\"\\n–ü—Ä–∏–º–µ—Ä—ã FN –æ—à–∏–±–æ–∫:\")\n",
    "    for idx, row in fn_errors.head(5).iterrows():\n",
    "        print(f\"\\n  {idx + 1}. {row['query'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tplexity-AFAH5PUx-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
